{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-12T14:33:01.095871Z",
     "start_time": "2025-05-12T14:33:01.088717Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, LlamaForCausalLM\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from typing import *\n",
    "import pandas as pd\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:33:01.160020Z",
     "start_time": "2025-05-12T14:33:01.140932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_gpt_model_and_tokenizer(model_name:str, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loads a huggingface model and its tokenizer\n",
    "\n",
    "    Parameters:\n",
    "    model_name: huggingface name of the model to load (e.g. GPTJ: \"EleutherAI/gpt-j-6B\", or \"EleutherAI/gpt-j-6b\")\n",
    "    device: 'cuda' or 'cpu'\n",
    "\n",
    "    Returns:\n",
    "    model: huggingface model\n",
    "    tokenizer: huggingface tokenizer\n",
    "    MODEL_CONFIG: config variables w/ standardized names\n",
    "\n",
    "    \"\"\"\n",
    "    assert model_name is not None\n",
    "\n",
    "    print(\"Loading: \", model_name)\n",
    "\n",
    "    if 'gpt-j' in model_name.lower():\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, low_cpu_mem_usage=True).to(device)\n",
    "\n",
    "        MODEL_CONFIG={\"n_heads\":model.config.n_head,\n",
    "                      \"n_layers\":model.config.n_layer,\n",
    "                      \"resid_dim\":model.config.n_embd,\n",
    "                      \"name_or_path\":model.config.name_or_path,\n",
    "                      \"attn_hook_names\":[f'transformer.h.{layer}.attn.out_proj' for layer in range(model.config.n_layer)],\n",
    "                      \"layer_hook_names\":[f'transformer.h.{layer}' for layer in range(model.config.n_layer)],\n",
    "                      \"prepend_bos\":False}\n",
    "\n",
    "    elif 'gpt2' in model_name.lower():\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "        MODEL_CONFIG={\"n_heads\":model.config.n_head,\n",
    "                      \"n_layers\":model.config.n_layer,\n",
    "                      \"resid_dim\":model.config.n_embd,\n",
    "                      \"name_or_path\":model.config.name_or_path,\n",
    "                      \"attn_hook_names\":[f'transformer.h.{layer}.attn.out_proj' for layer in range(model.config.n_layer)],\n",
    "                      \"layer_hook_names\":[f'transformer.h.{layer}' for layer in range(model.config.n_layer)],\n",
    "                      \"prepend_bos\":False}\n",
    "\n",
    "    elif 'gpt-neo-125m' in model_name.lower():\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "        MODEL_CONFIG={\"n_heads\":model.config.num_heads,\n",
    "                      \"n_layers\":model.config.num_layers,\n",
    "                      \"resid_dim\": model.config.hidden_size,\n",
    "                      \"name_or_path\":model.config.name_or_path,\n",
    "                      \"attn_hook_names\":[f'gpt_neo.layers.{layer}.attention.dense' for layer in range(model.config.num_layers)],\n",
    "                      \"layer_hook_names\":[f'gpt_neo.layers.{layer}' for layer in range(model.config.num_layers)],\n",
    "                      \"prepend_bos\":False}\n",
    "\n",
    "    elif 'gpt-neox' in model_name.lower() or 'pythia' in model_name.lower():\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16).to(device)\n",
    "\n",
    "        MODEL_CONFIG={\"n_heads\":model.config.num_attention_heads,\n",
    "                      \"n_layers\":model.config.num_hidden_layers,\n",
    "                      \"resid_dim\": model.config.hidden_size,\n",
    "                      \"name_or_path\":model.config.name_or_path,\n",
    "                      \"attn_hook_names\":[f'gpt_neox.layers.{layer}.attention.dense' for layer in range(model.config.num_hidden_layers)],\n",
    "                      \"layer_hook_names\":[f'gpt_neox.layers.{layer}' for layer in range(model.config.num_hidden_layers)],\n",
    "                      \"prepend_bos\":False}\n",
    "\n",
    "    elif 'llama' in model_name.lower():\n",
    "        if '70b' in model_name.lower():\n",
    "            # use quantization. requires `bitsandbytes` library\n",
    "            from transformers import BitsAndBytesConfig\n",
    "            bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_quant_type='nf4',\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_compute_dtype=torch.float16\n",
    "            )\n",
    "\n",
    "            access_token = \"hf_findNewOne\"\n",
    "\n",
    "            tokenizer = LlamaTokenizer.from_pretrained(model_name, token=access_token)\n",
    "            model = LlamaForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                quantization_config=bnb_config,\n",
    "                token=access_token\n",
    "            )\n",
    "        else:\n",
    "            if '7b' in model_name.lower() or '8b' in model_name.lower():\n",
    "                model_dtype = torch.float32\n",
    "            else: #half precision for bigger llama models\n",
    "                #This becomes only for the 13B model then. Okay then. What else?\n",
    "                model_dtype = torch.float16\n",
    "\n",
    "            # If transformers version is < 4.31 use LlamaLoaders\n",
    "            # tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "            # model = LlamaForCausalLM.from_pretrained(model_name, torch_dtype=model_dtype).to(device)\n",
    "\n",
    "            # If transformers version is >= 4.31, use AutoLoaders\n",
    "            access_token = \"hf_findNewOne\"\n",
    "\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=model_dtype, token=access_token).to(device)\n",
    "\n",
    "        MODEL_CONFIG={\"n_heads\":model.config.num_attention_heads,\n",
    "                      \"n_layers\":model.config.num_hidden_layers,\n",
    "                      \"resid_dim\":model.config.hidden_size,\n",
    "                      \"name_or_path\":model.config._name_or_path,\n",
    "                      \"attn_hook_names\":[f'model.layers.{layer}.self_attn.o_proj' for layer in range(model.config.num_hidden_layers)],\n",
    "                      \"layer_hook_names\":[f'model.layers.{layer}' for layer in range(model.config.num_hidden_layers)],\n",
    "                      \"prepend_bos\":True}\n",
    "    else:\n",
    "        raise NotImplementedError(\"Still working to get this model available!\")\n",
    "\n",
    "\n",
    "    return model, tokenizer, MODEL_CONFIG"
   ],
   "id": "93e5c009d02b05fc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:33:01.932728Z",
     "start_time": "2025-05-12T14:33:01.171042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_technical_name = \"EleutherAI/gpt-neo-125m\"\n",
    "#model_technical_name = 'gpt-2'\n",
    "\n",
    "model, tokenizer, model_config = load_gpt_model_and_tokenizer(model_technical_name)"
   ],
   "id": "e0b65f9c7296bd42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  EleutherAI/gpt-neo-125m\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:33:02.013212Z",
     "start_time": "2025-05-12T14:33:01.987747Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab['Asia']",
   "id": "45a918335796645a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38555"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:34:22.907737Z",
     "start_time": "2025-05-12T14:34:22.873549Z"
    }
   },
   "cell_type": "code",
   "source": "inputs = tokenizer('Asia', return_tensors=\"pt\")",
   "id": "37d943bf19b2da60",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:38:44.448495Z",
     "start_time": "2025-05-12T14:38:44.421294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_layer = model.transformer.wte\n",
    "static_embedding = embedding_layer(inputs[\"input_ids\"])"
   ],
   "id": "4a3bc992385488bd",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:38:48.166544Z",
     "start_time": "2025-05-12T14:38:48.151838Z"
    }
   },
   "cell_type": "code",
   "source": "static_embedding",
   "id": "67ca7b651c6737cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.9023e-01, -8.6328e-01,  1.8555e-01, -1.6406e-01, -2.8125e-01,\n",
       "           1.1182e-01,  4.5312e-01, -2.2070e-01,  5.2734e-01,  5.2344e-01,\n",
       "           3.6011e-03,  5.7422e-01,  3.7695e-01,  8.3594e-01, -4.6387e-02,\n",
       "          -1.3867e-01,  2.1289e-01, -2.9492e-01,  7.1289e-02, -6.6016e-01,\n",
       "           5.6250e-01,  3.5352e-01, -1.2354e-01,  4.7656e-01,  3.7109e-01,\n",
       "           7.4707e-02, -2.1582e-01, -1.6113e-01,  6.0156e-01, -1.5332e-01,\n",
       "          -1.8555e-02,  2.7930e-01,  1.7871e-01, -5.1562e-01, -1.0498e-01,\n",
       "           3.8086e-02,  1.2158e-01,  1.8457e-01, -1.7212e-02,  9.6875e-01,\n",
       "           2.0996e-01, -4.7461e-01, -4.3457e-02,  3.5547e-01,  7.1777e-02,\n",
       "           6.6895e-02, -1.0156e-01,  3.3398e-01, -4.8047e-01,  7.0312e-02,\n",
       "          -3.4180e-01, -1.8652e-01, -1.0205e-01,  2.0312e-01,  3.4961e-01,\n",
       "           5.4443e-02, -4.6484e-01, -1.5723e-01,  2.1582e-01,  2.9541e-02,\n",
       "          -5.5469e-01, -3.0273e-01, -5.4932e-02,  3.5742e-01,  1.5527e-01,\n",
       "          -3.6133e-01,  4.1016e-02, -6.3477e-02,  5.0781e-01, -7.8125e-01,\n",
       "           1.0645e-01,  3.0273e-01,  2.6758e-01,  2.3242e-01,  7.3438e-01,\n",
       "           6.3281e-01,  5.0391e-01,  4.5898e-01,  9.0332e-02, -1.9043e-02,\n",
       "          -1.2598e-01,  6.2988e-02, -1.7969e-01, -3.3203e-01,  1.1797e+00,\n",
       "           5.1172e-01, -4.7607e-02, -5.9766e-01,  7.3438e-01,  2.6367e-01,\n",
       "          -4.6875e-01, -2.0508e-01, -1.1094e+00, -4.2480e-02,  2.9102e-01,\n",
       "           5.1953e-01,  4.0283e-02, -2.5586e-01,  9.1797e-02, -1.8945e-01,\n",
       "          -2.7930e-01, -4.1748e-02,  3.9648e-01, -3.6523e-01, -5.0781e-01,\n",
       "          -3.3008e-01,  3.5400e-02,  9.3262e-02,  4.4922e-01,  3.4375e-01,\n",
       "           1.1768e-01, -2.2559e-01, -2.7734e-01,  8.6914e-02,  6.0303e-02,\n",
       "          -1.0400e-01, -2.8320e-01, -1.7090e-01, -1.4062e-01,  3.9453e-01,\n",
       "          -6.6895e-02,  3.0273e-01,  1.0059e-01, -2.1484e-01, -5.6641e-01,\n",
       "           4.3164e-01, -3.0664e-01, -3.0273e-01, -2.1484e-01, -1.1475e-01,\n",
       "           3.0859e-01,  2.4512e-01, -8.6719e-01,  2.3340e-01,  5.2344e-01,\n",
       "          -8.8379e-02,  7.7344e-01,  2.5781e-01, -1.9824e-01, -9.6680e-02,\n",
       "          -1.0498e-01, -3.4424e-02,  3.0273e-02, -7.1484e-01,  3.5352e-01,\n",
       "           5.8203e-01,  4.0234e-01,  4.1406e-01,  1.0791e-01,  1.3867e-01,\n",
       "          -1.6211e-01, -1.5430e-01,  2.9102e-01, -2.6172e-01,  2.8125e-01,\n",
       "           1.7480e-01,  8.5938e-01,  8.7402e-02,  1.4941e-01,  3.3398e-01,\n",
       "           1.1953e+00,  6.4062e-01, -1.7090e-01, -4.1992e-02, -2.3560e-02,\n",
       "           1.4941e-01,  2.6172e-01,  3.0273e-01,  2.8320e-01,  8.5449e-04,\n",
       "           2.8320e-01,  3.3203e-01,  7.5684e-02, -4.4727e-01,  2.7148e-01,\n",
       "          -3.7500e-01,  4.2578e-01, -6.9336e-02,  4.0039e-01,  3.7500e-01,\n",
       "           1.8120e-04, -3.6328e-01, -3.2031e-01, -4.4141e-01,  2.1118e-02,\n",
       "           2.1362e-02, -6.0547e-01,  3.7891e-01, -3.9258e-01,  4.3945e-01,\n",
       "           3.7500e-01,  2.7734e-01, -5.2246e-02, -1.9653e-02,  4.3164e-01,\n",
       "           6.8359e-01,  3.7695e-01, -6.1328e-01,  4.7852e-01, -3.9062e-01,\n",
       "           6.2891e-01,  2.2266e-01, -1.3281e-01, -2.0703e-01, -7.8516e-01,\n",
       "           9.5312e-01,  3.8672e-01,  1.7578e-02, -3.8086e-02, -1.4453e-01,\n",
       "           3.7891e-01,  8.7891e-01,  2.7734e-01,  1.4160e-01, -5.2734e-02,\n",
       "           4.1016e-01,  7.8125e-03, -2.1387e-01,  2.7734e-01,  3.1250e-01,\n",
       "          -3.5352e-01, -5.5859e-01,  1.6895e-01, -2.1875e-01,  6.0547e-02,\n",
       "          -4.6387e-02,  2.4316e-01, -6.9824e-02,  4.4336e-01,  3.1836e-01,\n",
       "          -1.8457e-01, -4.9609e-01,  3.5938e-01,  3.2617e-01,  1.7578e-01,\n",
       "          -6.4062e-01,  5.8984e-01, -9.2773e-02, -5.2734e-01,  2.1582e-01,\n",
       "           3.5156e-01, -3.0273e-01, -3.3789e-01, -3.0151e-02,  1.8281e+00,\n",
       "           1.6797e-01, -2.8516e-01,  7.8613e-02,  1.6992e-01,  1.3916e-02,\n",
       "           3.2422e-01,  9.1016e-01, -9.2188e-01, -3.0469e-01, -4.0771e-02,\n",
       "           4.8828e-02, -2.5391e-01,  3.9844e-01,  1.2793e-01,  1.5430e-01,\n",
       "           2.7148e-01,  3.4912e-02, -1.5918e-01,  4.7852e-01, -2.7100e-02,\n",
       "           6.7578e-01,  2.1387e-01,  4.4531e-01, -1.3281e-01,  2.5977e-01,\n",
       "          -2.4805e-01,  3.3398e-01,  4.0234e-01,  2.8711e-01,  2.9492e-01,\n",
       "           4.7363e-02,  6.1328e-01,  2.6562e-01, -8.5938e-01,  1.3184e-01,\n",
       "          -4.6289e-01,  8.4375e-01,  4.9609e-01, -3.2227e-02,  3.8574e-02,\n",
       "           1.7700e-02,  3.3984e-01,  7.1484e-01,  5.0391e-01, -5.5859e-01,\n",
       "           5.0781e-01, -2.6953e-01,  1.2158e-01,  2.6758e-01,  2.8125e-01,\n",
       "           1.7285e-01,  3.7500e-01,  1.9141e-01,  4.1602e-01,  2.9492e-01,\n",
       "           2.5391e-02,  9.6191e-02,  2.8711e-01,  2.8931e-02, -1.3770e-01,\n",
       "          -5.0000e-01,  6.0303e-02,  3.1445e-01,  1.1523e-01,  8.5938e-01,\n",
       "          -6.0156e-01,  4.8047e-01,  2.3926e-01,  2.6953e-01,  1.2422e+00,\n",
       "           9.4238e-02, -3.0664e-01,  4.4336e-01, -3.2617e-01, -2.6172e-01,\n",
       "          -3.5352e-01,  7.3047e-01, -7.0312e-02, -2.2656e-01,  4.1406e-01,\n",
       "           7.7344e-01,  4.3164e-01,  3.4180e-01,  2.0703e-01,  4.9023e-01,\n",
       "          -5.7812e-01,  9.1797e-02, -2.9102e-01,  3.7354e-02, -4.9219e-01,\n",
       "          -1.6846e-02,  7.5391e-01,  1.7676e-01,  1.6016e-01, -8.4473e-02,\n",
       "           2.6758e-01,  4.1016e-01,  6.0156e-01, -1.3770e-01, -3.9648e-01,\n",
       "           2.7930e-01, -1.7578e-01, -4.2773e-01,  5.6250e-01, -2.0508e-01,\n",
       "          -1.3086e-01,  3.8281e-01, -1.4355e-01, -1.0938e-01,  2.8125e-01,\n",
       "          -1.7383e-01,  4.9023e-01,  1.0859e+00, -7.0312e-01, -3.8086e-02,\n",
       "          -5.6641e-01,  3.5938e-01, -2.8320e-01,  5.4932e-02,  2.6562e-01,\n",
       "           7.7637e-02,  1.7871e-01,  3.2617e-01,  3.5547e-01, -1.7285e-01,\n",
       "           4.4727e-01,  3.5547e-01, -3.8477e-01, -2.7466e-02,  2.2656e-01,\n",
       "          -2.1777e-01,  1.3672e-01,  5.1172e-01,  6.0156e-01,  1.1230e-01,\n",
       "          -2.9883e-01, -1.8555e-01, -2.8442e-02, -6.9922e-01, -3.3203e-01,\n",
       "           2.6562e-01,  1.6699e-01,  7.4707e-02,  8.5547e-01,  4.6875e-01,\n",
       "           8.5547e-01,  1.1768e-01,  2.4609e-01, -1.2500e+00, -1.4746e-01,\n",
       "          -1.7090e-01,  6.8359e-01,  5.7031e-01,  1.7773e-01,  3.3008e-01,\n",
       "           6.3281e-01, -2.3145e-01,  1.5039e-01,  3.1055e-01, -2.4219e-01,\n",
       "          -8.3984e-02, -5.5469e-01,  3.4180e-01,  1.1328e-01, -2.8516e-01,\n",
       "           2.3926e-01,  6.8750e-01, -5.7812e-01,  3.6133e-01, -3.1445e-01,\n",
       "           4.2969e-01,  1.4551e-01, -3.1250e-01, -2.1875e-01,  4.0039e-01,\n",
       "           3.1494e-02,  9.9219e-01,  9.4141e-01, -9.3262e-02,  3.5352e-01,\n",
       "           2.9102e-01,  2.6758e-01, -4.8438e-01, -1.6895e-01, -3.8281e-01,\n",
       "          -3.9453e-01,  5.4297e-01,  5.9814e-02, -1.7212e-02,  2.2754e-01,\n",
       "          -4.1602e-01, -8.3008e-02, -5.3906e-01,  1.3281e-01, -2.7930e-01,\n",
       "          -1.1523e-01,  2.0215e-01,  8.7109e-01,  2.9883e-01, -7.6953e-01,\n",
       "           1.5625e-02, -7.3730e-02, -2.9785e-02,  8.7109e-01,  6.9824e-02,\n",
       "           7.7637e-02,  2.2705e-02,  4.1992e-01, -1.2500e-01, -9.1309e-02,\n",
       "          -2.5000e-01,  5.1562e-01,  2.5272e-05,  1.1084e-01,  9.9121e-02,\n",
       "          -1.4453e-01,  4.0625e-01,  6.2500e-01,  3.5547e-01,  8.1543e-02,\n",
       "          -2.1484e-01,  3.3398e-01,  3.5156e-02, -4.3945e-01,  5.1270e-02,\n",
       "           6.0547e-02,  3.0664e-01,  9.0820e-02,  3.4570e-01,  4.3945e-02,\n",
       "           1.0000e+00,  1.8750e-01,  2.3438e-01, -1.0254e-01, -2.3438e-01,\n",
       "          -3.7695e-01,  1.3867e-01,  6.2500e-01,  1.2012e-01, -3.4766e-01,\n",
       "           5.5908e-02, -8.6719e-01,  5.0781e-01, -2.4780e-02, -3.6914e-01,\n",
       "          -5.5664e-02,  3.6914e-01, -3.9795e-02, -2.5586e-01,  3.2812e-01,\n",
       "          -9.1406e-01,  1.7480e-01, -1.0352e-01, -1.0596e-01, -5.8594e-01,\n",
       "          -1.0625e+00, -1.4551e-01,  4.1797e-01,  4.8047e-01,  6.2891e-01,\n",
       "           4.8828e-01,  1.4551e-01,  1.1414e-02, -7.4463e-03, -2.0874e-02,\n",
       "          -7.1777e-02,  4.0625e-01, -4.7656e-01,  2.5977e-01,  1.3281e-01,\n",
       "           6.1768e-02, -3.6133e-01,  5.8838e-02,  2.7930e-01,  7.4609e-01,\n",
       "          -1.4648e-02, -1.0498e-01,  1.4531e+00,  4.8438e-01, -1.0859e+00,\n",
       "          -2.1191e-01, -9.5703e-02, -2.1289e-01, -3.6914e-01, -6.2500e-02,\n",
       "          -1.7090e-01, -3.0273e-01,  5.8203e-01,  3.0762e-02,  2.3828e-01,\n",
       "           4.6484e-01, -3.1445e-01,  6.2891e-01, -7.1289e-02,  7.6172e-01,\n",
       "           4.6875e-01,  7.3438e-01, -1.2329e-02,  9.4238e-02, -5.4932e-03,\n",
       "           3.4375e-01,  2.1582e-01, -4.6484e-01,  2.3633e-01,  5.8594e-01,\n",
       "          -2.1875e-01, -2.1582e-01,  2.6953e-01,  8.4473e-02, -3.7305e-01,\n",
       "          -2.9492e-01,  2.0312e-01,  7.4609e-01, -2.5000e-01,  1.0449e-01,\n",
       "          -6.6797e-01, -6.4453e-01,  1.7285e-01,  5.9082e-02,  3.1836e-01,\n",
       "           6.0547e-01,  3.8818e-02,  3.3594e-01, -4.6631e-02,  1.1914e-01,\n",
       "           3.4570e-01, -1.4648e-01,  3.0664e-01, -3.1128e-02, -1.6016e-01,\n",
       "          -2.1582e-01,  5.2734e-01, -2.7734e-01,  5.5664e-02,  3.5547e-01,\n",
       "          -2.0703e-01, -1.4355e-01,  4.7852e-01, -1.4453e-01,  2.9883e-01,\n",
       "           7.4707e-02, -3.5156e-01, -3.8477e-01, -2.8711e-01,  1.5234e-01,\n",
       "           3.5352e-01,  1.2109e+00, -1.6211e-01,  7.6172e-02, -4.4678e-02,\n",
       "           1.6699e-01,  9.8828e-01, -5.8984e-01,  2.4316e-01,  1.5430e-01,\n",
       "           3.5156e-01, -8.0566e-02,  4.9316e-02, -3.7305e-01,  2.4805e-01,\n",
       "           4.1992e-02,  3.6133e-01,  2.5586e-01, -3.7305e-01,  2.8711e-01,\n",
       "           6.6016e-01, -2.4805e-01,  2.6367e-01,  8.9453e-01, -3.3008e-01,\n",
       "          -1.8848e-01,  7.9590e-02, -2.5000e-01, -1.7188e-01, -1.1865e-01,\n",
       "           3.4180e-01, -1.8164e-01, -2.0410e-01,  1.6309e-01,  9.8145e-02,\n",
       "          -3.4766e-01,  4.0234e-01,  1.4062e-01,  1.7480e-01,  3.3008e-01,\n",
       "           1.1719e-01,  3.0664e-01,  2.4316e-01,  5.8838e-02,  8.3594e-01,\n",
       "           5.6250e-01,  3.1250e-01, -4.1992e-01,  1.5820e-01, -3.8281e-01,\n",
       "           2.4536e-02,  1.3086e-01,  1.6992e-01, -2.8320e-01, -2.1680e-01,\n",
       "           2.1582e-01, -5.3711e-02, -1.5703e+00, -3.9648e-01,  7.7344e-01,\n",
       "           6.1279e-02, -6.7188e-01, -7.6953e-01, -3.9453e-01, -7.1094e-01,\n",
       "           3.0273e-01,  8.9453e-01, -3.7305e-01,  6.4453e-01,  2.5195e-01,\n",
       "          -9.7656e-01, -1.5259e-02, -2.3071e-02, -4.3457e-02,  4.8340e-02,\n",
       "           6.6406e-02, -2.0996e-01, -9.6484e-01, -2.3926e-01,  6.9336e-02,\n",
       "          -1.4453e-01, -3.9258e-01,  7.0703e-01, -1.4587e-02, -1.8848e-01,\n",
       "           4.2188e-01, -1.8750e-01,  4.2578e-01, -2.3242e-01,  1.4551e-01,\n",
       "          -6.1719e-01, -2.8711e-01, -4.0430e-01,  2.6562e-01, -1.6846e-02,\n",
       "          -2.1191e-01,  9.9609e-01,  3.2812e-01,  1.6602e-01, -8.2520e-02,\n",
       "          -5.4297e-01, -2.1851e-02,  2.8711e-01, -3.8867e-01,  2.5977e-01,\n",
       "           7.2266e-02, -1.7188e-01, -7.8125e-01,  8.8867e-02, -5.1562e-01,\n",
       "           4.5654e-02, -1.8945e-01,  2.9297e-01,  7.6953e-01, -1.2012e-01,\n",
       "           2.0703e-01, -1.7383e-01, -1.2451e-01,  4.1797e-01,  1.5430e-01,\n",
       "           1.9531e-01, -3.2031e-01, -7.5781e-01,  2.1851e-02,  7.4219e-02,\n",
       "           1.4648e-03, -2.0996e-01,  2.3535e-01, -1.3281e-01, -3.0859e-01,\n",
       "          -4.6094e-01,  3.1836e-01,  1.9727e-01,  1.2500e-01,  3.0273e-01,\n",
       "           2.4902e-01, -1.7969e-01, -1.9922e-01, -4.8828e-01,  2.3926e-01,\n",
       "           2.7344e-01, -1.6113e-01,  2.7148e-01,  1.8750e-01, -4.4434e-02,\n",
       "          -2.8320e-01, -4.3335e-03,  1.3306e-02, -3.9258e-01, -1.5332e-01,\n",
       "           3.9551e-02, -9.1309e-02,  6.0547e-01,  6.7188e-01, -2.1680e-01,\n",
       "           4.1992e-01,  9.0625e-01, -5.3516e-01, -2.8906e-01,  2.6367e-01,\n",
       "           8.9062e-01, -3.3789e-01, -7.6172e-01,  8.1543e-02,  3.9453e-01,\n",
       "          -3.6133e-01,  4.6484e-01, -6.3477e-02,  8.0859e-01,  3.2959e-02,\n",
       "          -3.4375e-01,  5.7422e-01, -7.1289e-02, -3.8867e-01, -2.6562e-01,\n",
       "           2.9883e-01,  7.1094e-01, -9.5703e-02]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:41:03.752250Z",
     "start_time": "2025-05-12T14:41:03.745956Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_matrix = model.transformer.wte.weight",
   "id": "bf09cae4b10294cc",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:41:07.353726Z",
     "start_time": "2025-05-12T14:41:07.347596Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_matrix",
   "id": "956b342904059f64",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1709, -0.7383,  0.4277,  ...,  0.0840,  0.5820, -0.3457],\n",
       "        [ 0.2070, -0.6055,  0.4590,  ...,  0.1562,  0.4883, -0.2363],\n",
       "        [ 0.2324, -0.6367,  0.3262,  ...,  0.2236,  0.7500, -0.2354],\n",
       "        ...,\n",
       "        [ 0.7734, -1.1406,  0.6523,  ...,  0.2832,  0.9258, -0.5547],\n",
       "        [ 0.3906, -0.8438,  0.5117,  ...,  0.0148,  0.6992, -0.2383],\n",
       "        [ 0.2734, -0.7148,  0.2949,  ...,  0.1748,  0.4043, -0.3105]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:42:59.939281Z",
     "start_time": "2025-05-12T14:42:59.906748Z"
    }
   },
   "cell_type": "code",
   "source": "subsample = torch.randperm(model.config.vocab_size)[:5000].to(model.device)",
   "id": "63dd5eebb3dc7303",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:43:08.100547Z",
     "start_time": "2025-05-12T14:43:08.003580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_layer = model.transformer.wte\n",
    "subsampled_embeddings = embedding_layer(subsample)"
   ],
   "id": "cba5cab65647cf4e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:49:15.702899Z",
     "start_time": "2025-05-12T14:49:15.654499Z"
    }
   },
   "cell_type": "code",
   "source": "W_E_normed = subsampled_embeddings / subsampled_embeddings.norm(dim=-1, keepdim=True)",
   "id": "66228ce68773ff1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:49:21.790064Z",
     "start_time": "2025-05-12T14:49:21.641427Z"
    }
   },
   "cell_type": "code",
   "source": "cosine_sims = W_E_normed @ W_E_normed.T\n",
   "id": "83880ad648f6420e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:49:24.311296Z",
     "start_time": "2025-05-12T14:49:24.300760Z"
    }
   },
   "cell_type": "code",
   "source": "cosine_sims",
   "id": "95ccc02e2684f936",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9306, 0.8318,  ..., 0.8345, 0.8597, 0.8456],\n",
       "        [0.9306, 1.0000, 0.8563,  ..., 0.8721, 0.8763, 0.8769],\n",
       "        [0.8318, 0.8563, 1.0000,  ..., 0.9268, 0.9267, 0.9263],\n",
       "        ...,\n",
       "        [0.8345, 0.8721, 0.9268,  ..., 1.0000, 0.9187, 0.9150],\n",
       "        [0.8597, 0.8763, 0.9267,  ..., 0.9187, 1.0000, 0.9168],\n",
       "        [0.8456, 0.8769, 0.9263,  ..., 0.9150, 0.9168, 1.0000]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "898373fd638f4e2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
